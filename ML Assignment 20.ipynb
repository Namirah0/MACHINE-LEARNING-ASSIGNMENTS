{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea65fbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. What is the underlying concept of Support Vector Machines ?\n",
    "Ans:SVM or Support Vector Machine is a linear model for classification and regression problems. It can solve linear and \n",
    "    non-linear problems and work well for many practical problems. The idea of SVM is simple: The algorithm creates a line or \n",
    "    a hyperplane which separates the data into classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9713fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "2. What is the concept of a support vector ?\n",
    "Ans: Support vectors are data points that are closer to the hyperplane and influence the position and orientation of the \n",
    "    hyperplane. Using these support vectors, we maximize the margin of the classifier. Deleting the support vectors will change\n",
    "    the position of the hyperplane. These are the points that help us build our SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dab806e",
   "metadata": {},
   "outputs": [],
   "source": [
    "3. When using SVMs, why is it necessary to scale the inputs ?\n",
    "Ans: Because Support Vector Machine (SVM) optimization occurs by minimizing the decision vector w, the optimal hyperplane is \n",
    "    influenced by the scale of the input features and it's therefore recommended that data be standardized (mean 0, var 1) \n",
    "    prior to SVM model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710847d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "4. When an SVM classifier classifies a case, can it output a confidence score? What about a percentage chance ?\n",
    "Ans: An SVM classifier can give the distance between the test instance and the decision boundary as output, so we can use that\n",
    "    as a confidence score, but we cannot use this score to directly converted it into class probabilities.An SVM classifier can \n",
    "    output the distance between the test instance and the decision boundary, and you can use this as a confidence score. \n",
    "    However, this score cannot be directly converted into an estimation of the class probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad7364e",
   "metadata": {},
   "outputs": [],
   "source": [
    "5. Should you train a model on a training set with millions of instances and hundreds of features using the primal or dual form \n",
    "of the SVM problem ?\n",
    "Ans: So if there are millions of instances, you should definitely use the primal form, because the dual form will be much too \n",
    "    slow. 32. Say you trained an SVM classifier with an RBF kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167c6f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "6. Let's say you've used an RBF kernel to train an SVM classifier, but it appears to underfit the training collection. Is it \n",
    "better to raise or lower (gamma)? What about the letter C ?\n",
    "Ans: If SVM classifier underfits the training set, increasing gamma can help to capture more complex patterns in the data by making the decision boundary more flexible. Increasing C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa32779b",
   "metadata": {},
   "outputs": [],
   "source": [
    "7. To solve the soft margin linear SVM classifier problem with an off-the-shelf QP solver, how should the QP parameters \n",
    "(H, f, A, and b) be set ?\n",
    "Ans: The Support-vector Machine (or called Support-vector Networks initially by the author — Vladimir Vapnik) takes a completely different approach to solving statistical problems (in specific Classification). This algorithm has been heavily used in several classification problems like Image Classification, Bag-of-Words Classifier, OCR, Cancer prediction, and many more. SVM is basically a binary classifier, although it can be modified for multi-class classification as well as regression. Unlike logistic regression and other neural network models, SVMs try to maximize the separation between two classes of points. A brilliant idea is used by the author."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4100d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "8. On a linearly separable dataset, train a LinearSVC. Then, using the same dataset, train an SVC and an SGDClassifier. See if \n",
    "you can get them to make a model that is similar to yours ?\n",
    "Ans: Of course it depends on the dataset and of course a lot of other factors add weight but today in this small post I’ll demonstrate how to use LinearSVC , SVC classifier and SGD classifier via Python code and also compare results for the same dataset.\n",
    "\n",
    "Since classifiers are very sensitive to outliers we need to scale them but before we need to pick the right dataset, for simpler results I’ll showcase the benchmark dataset for all classifiers — the Iris dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317c6a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "9. On the MNIST dataset, train an SVM classifier. You'll need to use one-versus-the-rest to assign all 10 digits because SVM \n",
    "classifiers are binary classifiers. To accelerate up the process, you might want to tune the hyperparameters using small \n",
    "validation sets. What level of precision can you achieve ?\n",
    "Ans:The one-against-one classifier trains binary classifer for N class (multi class) data set. Each classifier recieves a pair of classes from the training set and we learn to classify between these two labels/classes. On the other hand, One versus Rest approach, we train on classifier per class, with the samples from that class labelled as Postive class and the rest as Negative class, and repeating these N times gives us a N class classifier. Now, all the samples are given Weights (probablity) for each class and from them we choose a winner class, giving the final Label. In order to perform Multi class classification we need to transform into a set of binary classification problem. When it comes to multi class classification The main difference between SVC and LinearSVC is they use One Vs One and One Vs Rest approach. One clear difference in SVC and Linear SVC is: SVC offers us different Kernels (rbf or poly) while LinearSVC just produces a linear margin of seperation. While in SVC the max iterations are infinite, LinearSVC limits them to 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94350312",
   "metadata": {},
   "outputs": [],
   "source": [
    "10. On the California housing dataset, train an SVM regressor ?\n",
    "Ans: The California housing market sizzled last year to break all records. It was a hot seller’s real estate market. With this in mind, this is what we are going to do today: "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
